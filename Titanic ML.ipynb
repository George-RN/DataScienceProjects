{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7652cd4a",
   "metadata": {},
   "source": [
    "This notebook has the code for the Kaggle Titanic ML project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdced838",
   "metadata": {},
   "source": [
    "First, the two sets of data are imported into test and train variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6e8b8",
   "metadata": {},
   "source": [
    "Once the two data sets are imported, I call .head() to get an overview of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5318f99",
   "metadata": {},
   "source": [
    "There are 12 data columns in the train data, with the test data missing the 'Survived' column as these are the values that need to be predicted. An overview of the data suggests that some cleaning will be necessary. 'Cabin', for example, contains a number of NaN values. The NaN values will be ammended in a later step, but for this analysis I chose to drop 'Cabin'. The column 'Pclass' contains the passenger class, which may be a better indicator of the passenger class than the cabin location, so 'Cabin' will be dropped in the this analysis. Similarly, I will exclude 'Fare', 'Ticket', 'Parch' and 'SibSp' as these do not seem overtly associated with survival rates in contrast to the other columns. These are saved in a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd56019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = train_data[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"Survived\"]]\n",
    "test_data_set = test_data[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8777fb",
   "metadata": {},
   "source": [
    "From the review of the data, the 'Sex' column is given as a string. This will need changing from a categorical variable to a continuous variable so that the classification model can be called later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "label_train_data = train_data_set.apply(label.fit_transform)\n",
    "label_test_data = test_data_set.apply(label.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc9176",
   "metadata": {},
   "source": [
    "The remaining data is checked to ensure that it is complete by searching for NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_set.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce13e8",
   "metadata": {},
   "source": [
    "It yields 2 values in 'Embarked' and 177 in 'Age'. These can be amended by using sklearn's imputer function to apply an average. Once this is done the original headings will need to be returned as these were lost in the imputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer()\n",
    "imputed_train_data = pd.DataFrame(my_imputer.fit_transform(label_train_data))\n",
    "imputed_test_data = pd.DataFrame(my_imputer.fit_transform(label_test_data))\n",
    "\n",
    "imputed_test_data.columns = test_data_set.columns\n",
    "imputed_train_data.columns = train_data_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0d24b",
   "metadata": {},
   "source": [
    "The data is now ready to be passed to a model. In order to fine tune the model, I need test values for both the x and y variables (the data loaded from train.csv in imputed_test_data does not have the y data for survival). I need this so I can calculate error and determine what parameters for the model yield the best results. First, I split imputed_train_data into test and train variables so that I can begin to fine tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe428bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X = imputed_train_data[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]]\n",
    "imputed_y = imputed_train_data[[\"Survived\"]]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(imputed_X, imputed_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25023e9c",
   "metadata": {},
   "source": [
    "The predicition is whether or not the passengers survive - as there can only be one of two outcomes, a classification model will be best suited to make predictions. The random forest provides multiple models and finds the average result from these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa273c9",
   "metadata": {},
   "source": [
    "To test for the mean squared error, I will first fit the model with the training data in train_X and train_y. I can then call .predict() with the test data and view the mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08939396",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model.fit(train_X, train_y)\n",
    "print(f'MAE of forest is: {mean_squared_error(forest_model.predict(test_X), test_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c602e1a",
   "metadata": {},
   "source": [
    "Using a function to get the mean squared error and a loop, different values can be passed to the parameters of the random forest. This will help get an idea of which parameters provide the most accurate classifcation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(estimators, samples, depth, train_X, train_y):\n",
    "    model = RandomForestClassifier(n_estimators=estimators, max_depth=depth, max_samples=samples, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    print(f'MAE of forest with {depth} depth, {estimators} estimators, and {samples}, samples is: {mean_squared_error(model.predict(test_X), test_y)}')\n",
    "    \n",
    "depths = [3, 6, 9, 12, 15]\n",
    "\n",
    "for entry in depths:\n",
    "    get_mae(500, 10, entry, train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc476e3",
   "metadata": {},
   "source": [
    "After fine-tuning to look for the most accuracy from the random forest, I added these parameters to forest_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d955299",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=700, max_depth=12, max_samples = 20, random_state=1)\n",
    "forest_model.fit(imputed_train_data[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]], imputed_train_data[['Survived']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27044279",
   "metadata": {},
   "source": [
    "This model can then be used to predict the test data for passenger survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf76172",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_model.predict(imputed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c25c3",
   "metadata": {},
   "source": [
    "Finally, I converted these values to .csv to be submitted to Kaggle to check how well the model did. This model received 0.77. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.astype(int)})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
